# Start Here - Spectra App Development Guide

## ğŸ¯ Welcome to Spectra App Development

Welcome to the Spectra App project! This guide will help you get started with development and understand our workflow. Whether you're implementing new features, fixing bugs, or exploring the codebase, this document is your starting point.

## ğŸ“‹ Essential Reading (Start Here)

### Core Documentation
- **`docs/history/MASTER PROMPT.md`** - Comprehensive product specification and acceptance criteria
  - Defines the application's vision, architecture, and scientific goals
  - Outlines non-negotiable principles, Atlas alignment, and calibration/identification mandates
  - Contains detailed feature requirements and validation criteria drawn from the pass reviews

- **`docs/history/RUNNER_PROMPT.md`** - Development workflow and iteration loop
  - Describes the plan â†’ implement â†’ test â†’ document â†’ PR cycle
  - Explains our docs-first development philosophy
  - Provides guidance for AI-assisted development sessions

### Quick Reference
- **`README.md`** - Project overview, installation, and basic usage
- **`AGENTS.md`** - Development guidelines, spectroscopy conventions, UI contract expectations
- **`docs/brains/README.md`** - How to log architectural decisions now that `atlas/brains.md` has been decomposed
- **`docs/link_collection.md`** - Curated spectroscopy resources to cite when sourcing new data
- **`docs/reviews/pass1.md` â€¦ `docs/reviews/pass4.md`** - Review dossiers outlining calibration, identification, provenance, and UI priorities

## ğŸš€ Getting Started

### 1. Environment Setup
```bash
# Quick start (Windows)
RunSpectraApp.cmd

# Manual setup
py -3.11 -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Verify Installation
```bash
# Run tests to verify everything works
pytest

# Launch the application
python -m app.main
```

### 3. Explore the Codebase
- **`app/`** - Main application code (PySide6/Qt)
- **`tests/`** - Test suite (pytest)
- **`samples/`** - Spectroscopy sample data (lamps, forthcoming standards) grouped by instrument/type
- **`specs/`** - Technical specifications (provenance schema, UI contracts)
- **`docs/brains/`** - Timestamped architectural decisions tied back to the Atlas

## ğŸ”„ Development Workflow

### Phase 1: Planning & Documentation
1. **Review Existing Context**
   - Read `docs/history/MASTER PROMPT.md`, `AGENTS.md`, and `docs/reviews/pass*.md`
   - Consult `docs/history/KNOWLEDGE_LOG.md` and `docs/brains/` for the latest decisions
   - Review `docs/reviews/workplan.md`, backlog queues, and brainstorming notes before scoping new work

2. **Create Work Plan**
   ```bash
   # Create or update your development workplan
   docs/reviews/workplan.md
   ```
   - Break down tasks into small, atomic units aligned with Atlas chapters
   - Define acceptance criteria (behaviour, docs, tests, provenance) for each task
   - Identify documentation, brains entries, and test updates before coding

### Phase 2: Implementation Loop
Follow the **RUNNER_PROMPT** workflow for each development session:

1. **Plan** - Review goals and constraints from MASTER_PROMPT
2. **Implement** - Code with docs-first approach
3. **Test** - Run pytest suite and verify functionality
4. **Document** - Update all relevant documentation
5. **Review** - Self-review against acceptance criteria

### Phase 3: Quality Assurance
- **Run Full Test Suite**: `pytest -v`
- **Verify UI Responsiveness**: Test with 1M+ point datasets
- **Check Documentation**: Ensure all changes are documented
- **Log Changes**: Update `docs/history/PATCH_NOTES.md` and
  `docs/history/KNOWLEDGE_LOG.md` with real timestamps
- **Release Prep**: Follow `packaging/windows_build.md` if a distribution build
  or version bump is required

## ğŸ“ Creating Your Workplan

Create or update `docs/reviews/workplan.md` with this template:

```markdown
# Development Workplan - [Your Name/Feature]

## Overview
Brief description of the feature or fix being implemented.

## Tasks
- [ ] Task 1: Description
- [ ] Task 2: Description 
- [ ] Task 3: Description

## Acceptance Criteria
- [ ] All tests pass (pytest)
- [ ] UI remains responsive with large datasets
- [ ] Documentation updated
- [ ] Patch notes and knowledge log updated
- [ ] No regression in existing functionality

## References
- Related issues: #[issue numbers]
- Documentation: [links to relevant docs]
- Technical specs: [links to specs]
```

## ğŸ›  Branch Strategy

1. **Create Feature Branch**
   ```bash
   git checkout -b feature/your-feature-name
   ```

2. **Follow Atomic PR Principles**
   - Small, focused changes
   - Comprehensive documentation
   - Complete test coverage
   - Clear commit messages

3. **PR Checklist**
   - [ ] All tests pass
   - [ ] Documentation updated
   - [ ] UI contract preserved (if UI changes)
   - [ ] Performance validated
   - [ ] Patch notes included

## ğŸ¯ Key Development Principles

### Non-Negotiable Rules
- **Desktop First**: PySide6/Qt only - no web components
- **Offline-First Data**: All data cached locally, persists across sessions
- **Unit Canon**: Store raw data in nanometers, convert at display time only
- **Provenance Everywhere**: Complete audit trail for all operations
- **Docs-First**: Documentation precedes implementation

### Quality Standards
- **Performance**: UI must remain responsive with 1M+ point datasets
- **Scientific Accuracy**: All algorithms must be mathematically sound
- **User Experience**: Clean, intuitive interface that doesn't overwhelm
- **Maintainability**: Modular, tested, documented code

## ğŸ” Exploring Further

### For UI Development
- Review `specs/ui_contract/` for component specifications
- Study existing UI patterns in `app/ui/`
- Verify against the UI contract in `agents.md`

### For Data Processing
- Examine `app/services/` for ingestion and analysis services
- Review unit conversion patterns in `app/services/units/`
- Study provenance tracking in `app/services/provenance/`

### For Testing
- Explore existing tests in `tests/` for patterns
- Check `specs/testing/` for testing strategy
- Verify performance with large datasets in `tests/performance/`

## ğŸ†˜ Getting Help

- **Documentation**: Check `docs/` directory first
- **AI Logs**: Review `docs/ai_log/` for similar past work
- **Technical Specs**: Consult `specs/` for architecture decisions
- **Test Suite**: Use tests as living documentation

## ğŸ‰ Next Steps

1. âœ… Read MASTER_PROMPT and RUNNER_PROMPT
2. âœ… Set up development environment
3. âœ… Create your workplan in `docs/reviews/workplan.md`
4. ğŸ”„ Start development loop with small, atomic changes
5. ğŸ“ Document everything as you go
6. ğŸ§ª Test thoroughly before committing
7. ğŸ”€ Open PR when all criteria are met

---

**Remember**: Work in small batches, document everything, and keep the tests passing. Welcome to the Spectra App project! ğŸš€